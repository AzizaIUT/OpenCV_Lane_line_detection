{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senior Challengers: Lane Lines Detection using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary libraries\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line argument 1st = Input video file name 2nd = Output video file name 3rd = Output contour file name\n",
    "args = sys.argv\n",
    "\n",
    "if len(args) == 1:\n",
    "    sys.exit(1)\n",
    "    \n",
    "input_file = args[1]\n",
    "\n",
    "output_file = None\n",
    "contour_file = None\n",
    "if len(args) >= 3:\n",
    "    output_file = args[2]\n",
    "if len(args) == 4:\n",
    "    contour_file = args[3]\n",
    "prev_left_avg = [0.000001, 0] \n",
    "prev_right_avg = [0.000001, 0] \n",
    "direction = \"Straight\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_slope_intercept(img, lines):\n",
    "    left_points = []\n",
    "    right_points = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "\n",
    "            parameters = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope = parameters[0]\n",
    "            intercept = parameters[1]\n",
    "\n",
    "            # we can differentiate lines whether on right or lefft by their slope values:\n",
    "            if slope < 0:  # points on the left have negative slope\n",
    "                left_points.append((slope, intercept))  # so we add these points to our left_points array\n",
    "            else:\n",
    "                right_points.append((slope, intercept))  # else these points are on the right side\n",
    "\n",
    "            # to draw the continuous line we have to find averages of these left or right points arrays\n",
    "            left_points_avg = np.average(left_points,\n",
    "                                         axis=0)  # axis should be 0 because we want averages of columns in array\n",
    "            right_points_avg = np.average(right_points, axis=0)\n",
    "\n",
    "            # we need the coordinates to draw the line:\n",
    "            right_line = make_coordinates(img, right_points_avg)\n",
    "            left_line = make_coordinates(img, left_points_avg)\n",
    "\n",
    "            return np.array([left_line, right_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_yellow_white(frame):\n",
    "    # Apply masks for white and yellow lines\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # the limits for white color\n",
    "    lower_white = np.array([0, 0, 100], dtype=np.uint8) # the lower limit\n",
    "    upper_white = np.array([255, 255, 255], dtype=np.uint8) # the upper limit\n",
    "    # the mask of the only white color of the frame\n",
    "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    \n",
    "    # the limits of yellow color\n",
    "    lower_yellow = np.array([20, 100, 100], dtype=np.uint8) # the lower limit\n",
    "    upper_yellow = np.array([30, 255, 255], dtype=np.uint8) # the upper limit\n",
    "    # the mask of the only yellow color of the frame\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    \n",
    "    # merge both masks into one mask\n",
    "    mask = cv2.bitwise_or(mask_white, mask_yellow)\n",
    "    # apply the masks to the frame\n",
    "    frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    # return the frame with only white and yellow colors\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_image(frame):\n",
    "    # frame -> gray image \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    # GaussianBlur\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    # Convert the frame to BINARY image (black and white)\n",
    "    binary = cv2.threshold(blur, 110, 255, cv2.THRESH_BINARY)[1]\n",
    "    canny = cv2.Canny(binary, 100, 150)\n",
    "    \n",
    "    return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract only the lower part of the image\n",
    "def roi(frame):\n",
    "    \n",
    "    height = frame.shape[0] # height\n",
    "    width = frame.shape[1] # width\n",
    "    # polygon \n",
    "    polygons = np.array([\n",
    "                            [(5 * width//16, height), \n",
    "                             (6 * width // 16, 7 * height//9),  \n",
    "                             (10 * width // 16, 7 * height//9), \n",
    "                             (14*width//16, height)] \n",
    "                        ])\n",
    "    \n",
    "    mask = np.zeros_like(frame)\n",
    "    # polygons filling\n",
    "    cv2.fillPoly(mask, polygons, 255)\n",
    "    segment = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    left = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# function to identify the lines on the frames from Hough Lines \n",
    "def measure_l(frame, lines):\n",
    "    global prev_left_avg, prev_right_avg \n",
    "    if lines is None:\n",
    "        return frame\n",
    "    \n",
    "    left = []\n",
    "    right = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Reshapes line from 2D array to 1D array of size 4\n",
    "        x1, y1, x2, y2 = line.reshape(4)\n",
    "        parameters = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "        # extract the slope and y-intecept separately\n",
    "        slope = parameters[0]\n",
    "        y_intercept = parameters[1]\n",
    "   \n",
    "        if slope < 0:\n",
    "            left.append((slope, y_intercept)) # left line\n",
    "        else:\n",
    "            right.append((slope, y_intercept)) # right line\n",
    "        \n",
    "    # average of the left and right lines into a single slope and y-intercept value\n",
    "    left_avg = np.average(left, axis = 0) # the slope\n",
    "    right_avg = np.average(right, axis = 0) # the y-incercept\n",
    "\n",
    "    if type(left_avg) == np.ndarray:\n",
    "        prev_left_avg = left_avg\n",
    "    else: \n",
    "        left_avg = prev_left_avg\n",
    "\n",
    "    if type(right_avg) == np.ndarray:\n",
    "        prev_right_avg = right_avg\n",
    "    else: \n",
    "        right_avg = prev_right_avg\n",
    "        \n",
    "    # Find the x1, y1, x2, y2 coordinates for the left and right lines\n",
    "    left_line = coordinates(frame, left_avg)\n",
    "    right_line = coordinates(frame, right_avg)\n",
    "\n",
    "    return np.array([left_line, right_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinates of the lines in the frame\n",
    "def coordinates(frame, line_params):\n",
    "    # extract the slope and y-intercept from the line\n",
    "    try:\n",
    "        slope, intercept = line_params\n",
    "    except:\n",
    "        slope, intercept = 0, 0\n",
    "   \n",
    "    if slope == 0:\n",
    "        y1 = frame.shape[0]\n",
    "        y2 = frame.shape[0]\n",
    "        x1 = frame.shape[1] / 2\n",
    "        x2 = frame.shape[1] / 2\n",
    "    else: \n",
    "        y1 = frame.shape[0]\n",
    "       \n",
    "        y2 = int(y1 - frame.shape[0]*0.2)\n",
    "        x1 = int((y1 - intercept) / slope)\n",
    "        x2 = int((y2 - intercept) / slope)\n",
    "    \n",
    "    return np.array([x1, y1, x2, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the lines on the rame\n",
    "def visualize_lines(frame, lines):\n",
    "    # Create an empty image of the same size as the frame filled with the zeros\n",
    "    lines_visualize = np.zeros_like(frame)\n",
    "    f_points = [] # find the points for drawing the colored polygon\n",
    "    \n",
    "    # Create an empty image of the same size as the frame filled with the zeros\n",
    "    mask = np.zeros_like(frame)\n",
    "    \n",
    "    # if there are no lines, return the empty frame without any changes \n",
    "    if lines is None:\n",
    "        return frame\n",
    "    \n",
    "    # loop through each set of coordinates as the lines \n",
    "    for x1, y1, x2, y2 in lines:\n",
    "        # Draws lines between two coordinates with green color and 5 thickness\n",
    "        cv2.line(lines_visualize, (x1, y1), (x2, y2), (0, 200, 0), 5)\n",
    "        # append the points of the lines for the rectangle\n",
    "        f_points.append((x2, y2)) \n",
    "        f_points.append((x1, y1))\n",
    "\n",
    "    # create an empty array to rearrange the points of the polygon \n",
    "    points = []\n",
    "    points.append(f_points[0]) \n",
    "    points.append(f_points[1])\n",
    "    points.append(f_points[3])\n",
    "    points.append(f_points[2])\n",
    "\n",
    "    # draw the polygon with the given points with filled with red color on the mask\n",
    "    cv2.fillPoly(mask, np.array([points]), (0, 0, 255))\n",
    "    \n",
    "    # return the frame filled the drawn lines and the polygon on it\n",
    "    return cv2.bitwise_or(lines_visualize, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to find the direction of the car movement \n",
    "def find_direction(lines):\n",
    "    global direction \n",
    "    slopes = []\n",
    "\n",
    "    if lines is None:\n",
    "        return direction\n",
    "    if len(lines) > 2:\n",
    "        return direction\n",
    " \n",
    "    for x1, y1, x2, y2 in lines.reshape(2, 4):\n",
    "        slopes.append(np.arctan((y2-y1) / (x2-x1)) * 180 / np.pi)\n",
    "\n",
    "    if slopes[0] < -55 and slopes[1] < 41:\n",
    "        direction = \"left\" # left direction\n",
    "    elif slopes[0] > -50 and slopes[1] > 48:\n",
    "        direction = \"right\" # right direction\n",
    "    else:\n",
    "        direction = \"straight\" # default direction\n",
    "\n",
    "\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video(w, h):\n",
    "    global direction # use the global variable\n",
    "    cap = cv2.VideoCapture(\"input_video.mp4\") # read the video named \"Road.mp4\" \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) # find the FPS of the video\n",
    "    \n",
    "    # while the camera is openned \n",
    "    while (cap.isOpened()):\n",
    "        # store the starting time before the frame processing\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            try: \n",
    "                frame = cv2.resize(frame, (w, h))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                frame[:,:,2] -= 20\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "                extract = extract_yellow_white(frame)\n",
    "                \n",
    "                canny = canny_image(extract)\n",
    "\n",
    "                # region of interest\n",
    "                segment = roi(canny)\n",
    "                \n",
    "                # hough lines \n",
    "                hough = cv2.HoughLinesP(segment, 1, np.pi / 180, 25, np.array([]), minLineLength = 25, maxLineGap = 50)           \n",
    "                lines = measure_l(frame, hough)\n",
    "\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                # make it lighter by rising the brightness by 20\n",
    "                frame[:,:,2] += 20\n",
    "                # convert back to BGR color spaces\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "       \n",
    "                direction = find_direction(lines)\n",
    "                # Drawing the lines on the frame\n",
    "                lines_visualize = visualize_lines(frame, lines)\n",
    "\n",
    "                output = cv2.addWeighted(frame, 1, lines_visualize, 1, 1)\n",
    "            except:\n",
    "                # the case if some error occurs during the execution of the functions\n",
    "                output = frame\n",
    "        else:\n",
    "            # the case if the video has ended\n",
    "            break\n",
    "    \n",
    "        # store the ending time after the frame processing\n",
    "        end_time = time.time()\n",
    "        text = \"DIRECTION: {}\".format(direction.upper())\n",
    "        org = (10, 25)\n",
    "        fontFace = cv2.FONT_HERSHEY_PLAIN\n",
    "        fontScale = 1\n",
    "        color = (0, 0, 255)\n",
    "        thickness = 1\n",
    "        output = cv2.putText(output, text, org, fontFace, fontScale, color, thickness)\n",
    "        # FPS  \n",
    "        text = \"FPS: {}\".format(int(1/(end_time - start_time)))\n",
    "        org = (10, 50)\n",
    "\n",
    "        # put the FPS text on the frame\n",
    "        output = cv2.putText(output, text, org, fontFace, fontScale, color, thickness)\n",
    "\n",
    "        # Opens a new window and displays the output frame\n",
    "        cv2.imshow(\"outout_video.mp4\", output)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "video(w=640, h=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
